# -*- coding: utf-8 -*-
"""WORKOUT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wS2Wae8N3oAxqH8V7m2vFe9BijlUUAJz
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/My\ Drive/

!ls /content/drive/My\ Drive/122Colab/

file_path = "/content/drive/My Drive/megaGymDataset.csv"

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from google.colab import drive
drive.mount('/content/drive')

file_path = "/content/drive/My Drive/megaGymDataset.csv"

import os
print(os.path.exists(file_path))

!ls /content/drive/My\ Drive/

!ls /content/drive/My\ Drive/122Colab/

import pandas as pd

file_path = "/content/drive/My Drive/megaGymDataset.csv"  # Update path if needed

try:
    df = pd.read_csv(file_path)
    print("File loaded successfully!")
    print(df.head())  # Show first few rows
except FileNotFoundError:
    print("Error: File not found. Check the file path!")
except Exception as e:
    print(f"Error: {e}")  # Print other possible errors

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/My\ Drive/

!ls /content/drive/My\ Drive/122Colab/

file_path = "/content/drive/My Drive/122Colab/megaGymDataset.csv"  # Adjust if inside a folder

import pandas as pd

try:
    df = pd.read_csv(file_path)
    print("‚úÖ File loaded successfully!")
    print(df.head())  # Show first few rows
except FileNotFoundError:
    print("‚ùå Error: File not found. Check the file path carefully!")
except Exception as e:
    print(f"‚ö†Ô∏è Other error: {e}")

df = pd.read_csv(file_path)

df.drop(columns=["Unnamed: 0", "Desc", "RatingDesc"], inplace=True)

df["Rating"].fillna(df["Rating"].median(), inplace=True)

label_encoders = {}
for col in ["Type", "BodyPart", "Equipment", "Level"]:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

X = df.drop(columns=["Level"])  # Predicting Level
y = df["Level"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier  # Change if regression is needed
from sklearn.metrics import accuracy_score, classification_report

file_path = "/content/drive/My Drive/122Colab/megaGymDataset.csv"
df = pd.read_csv(file_path)

print(df.info())  # Check columns, types, and missing values
print(df.head())

label_encoders = {}
for column in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

target_column = 'Type'  # <-- CHANGE THIS based on dataset
X = df.drop(columns=[target_column])
y = df[target_column]

scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
print(classification_report(y_test, y_pred))

from google.colab import drive
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

drive.mount('/content/drive')

file_path = "/content/drive/My Drive/122Colab/megaGymDataset.csv"
df = pd.read_csv(file_path)

print(df.info())
print(df.head())

print(df.info())
print(df.head())

le_bodypart = LabelEncoder()
le_type = LabelEncoder()
le_level = LabelEncoder()
le_equipment = LabelEncoder()

df['BodyPart'] = le_bodypart.fit_transform(df['BodyPart'])
df['Type'] = le_type.fit_transform(df['Type'])
df['Level'] = le_level.fit_transform(df['Level'])
df['Equipment'] = le_equipment.fit_transform(df['Equipment'])

X = df[['BodyPart', 'Type', 'Level']]  # Input Features
y = df['Equipment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

WORKOUT_RULES = {
    'sets': {'Beginner': 3, 'Intermediate': 4, 'Expert': 5},
    'reps': {'Beginner': '12-15', 'Intermediate': '8-12', 'Expert': '5-8'}
}

def generate_workout_plan(bodypart, workout_type, level, days_per_week=3):
    try:
        # Encode user input safely
        if bodypart not in le_bodypart.classes_:
            raise ValueError(f"Unknown BodyPart: {bodypart}")
        if workout_type not in le_type.classes_:
            raise ValueError(f"Unknown Workout Type: {workout_type}")
        if level not in le_level.classes_:
            raise ValueError(f"Unknown Level: {level}")

        bodypart_enc = le_bodypart.transform([bodypart])[0]
        type_enc = le_type.transform([workout_type])[0]
        level_enc = le_level.transform([level])[0]

        # Predict Equipment
        equipment_pred = model.predict([[bodypart_enc, type_enc, level_enc]])
        equipment_name = le_equipment.inverse_transform(equipment_pred)[0]

        # Get sets & reps based on experience level
        exp_sets = WORKOUT_RULES['sets'][level]
        exp_reps = WORKOUT_RULES['reps'][level]

        # Create Workout Schedule
        schedule = {}
        for i in range(days_per_week):
            schedule[f"Day {i+1}"] = [
                f"{equipment_name}: {exp_sets} sets x {exp_reps} reps"
            ]

        return schedule

    except Exception as e:
        print(f"‚ö†Ô∏è Error: {e}")
        return None

# Example Usage
user_input = {
    'bodypart': 'Abdominals',   # e.g., Chest, Back, Legs, etc.
    'workout_type': 'Push',  # e.g., Push, Pull, Core
    'level': 'Intermediate', # Beginner, Intermediate, Expert
    'days_per_week': 4
}

plan = generate_workout_plan(**user_input)

# Print Results
if plan:
    print("\nüî• Weekly Workout Plan üî•")
    for day, exercises in plan.items():
        print(f"\n{day}:")
        for ex in exercises:
            print(f"- {ex}")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from google.colab import drive

# Step 1: Mount Google Drive
drive.mount('/content/drive')

# Step 2: Load Dataset from Google Drive
file_path = "/content/drive/My Drive/122Colab/megaGymDataset.csv"
df = pd.read_csv(file_path)

# Step 3: Clean Data
df = df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)  # Standardize text format
df.fillna(df.mode().iloc[0], inplace=True)  # Fill missing values

# Step 4: Encode Categorical Variables
le_bodypart = LabelEncoder()
le_level = LabelEncoder()
le_equipment = LabelEncoder()

df['BodyPart'] = le_bodypart.fit_transform(df['BodyPart'])
df['Level'] = le_level.fit_transform(df['Level'])
df['Equipment'] = le_equipment.fit_transform(df['Equipment'])

# Step 5: Train Model
X = df[['BodyPart', 'Level']]  # Removed 'Type'
y = df['Equipment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 6: Workout Rules
WORKOUT_RULES = {
    'sets': {'beginner': 3, 'intermediate': 4, 'expert': 5},
    'reps': {'beginner': '12-15', 'intermediate': '8-12', 'expert': '5-8'}
}

# Step 7: Function to Generate Workout Plan
def generate_workout_plan(bodypart, level, days_per_week=3):
    try:
        # Convert user input to lowercase & remove spaces
        bodypart = bodypart.strip().lower()
        level = level.strip().lower()

        # DEBUG: Print available categories
        print("Available BodyParts:", list(le_bodypart.classes_))  # Debugging step

        # Check if inputs exist
        if bodypart not in le_bodypart.classes_:
            raise ValueError(f"‚ö†Ô∏è Unknown BodyPart: {bodypart}")
        if level not in le_level.classes_:
            raise ValueError(f"‚ö†Ô∏è Unknown Level: {level}")

        # Encode inputs
        bodypart_enc = le_bodypart.transform([bodypart])[0]
        level_enc = le_level.transform([level])[0]

        # Predict Equipment
        equipment_pred = model.predict([[bodypart_enc, level_enc]])
        equipment_name = le_equipment.inverse_transform(equipment_pred)[0]

        # Get sets & reps
        exp_sets = WORKOUT_RULES['sets'][level]
        exp_reps = WORKOUT_RULES['reps'][level]

        # Create Workout Schedule
        schedule = {}
        for i in range(days_per_week):
            schedule[f"Day {i+1}"] = [
                f"{equipment_name}: {exp_sets} sets x {exp_reps} reps"
            ]

        return schedule

    except Exception as e:
        print(f"‚ö†Ô∏è Error: {e}")
        return None

# Example Usage
user_input = {
    'bodypart': 'Lats',   # Ensure lowercase
    'level': 'expert',
    'days_per_week': 6
}

plan = generate_workout_plan(**user_input)

# Print Results
if plan:
    print("\nüî• Weekly Workout Plan üî•")
    for day, exercises in plan.items():
        print(f"\n{day}:")
        for ex in exercises:
            print(f"- {ex}")

import pandas as pd

# Load the new dataset
file_path_new = "/content/drive/My Drive/122Colab/gym_members_exercise_tracking.csv"
df_new = pd.read_csv(file_path_new)

# Display the first few rows
print(df_new.info())
print(df_new.head())

import pandas as pd

# Load the original dataset
file_path_old = "/content/drive/My Drive/122Colab/megaGymDataset.csv"
df_old = pd.read_csv(file_path_old)

# Load the new dataset
file_path_new = "/content/drive/My Drive/122Colab/gym_members_exercise_tracking.csv"
df_new = pd.read_csv(file_path_new)

# Check column names
print("Old Dataset Columns:", df_old.columns)
print("New Dataset Columns:", df_new.columns)

# Display first few rows
print(df_old.head())
print(df_new.head())

print("Old Dataset Columns:", df_old.columns.tolist())
print("New Dataset Columns:", df_new.columns.tolist())

df_old.rename(columns={'Muscle Group': 'BodyPart'}, inplace=True)
df_new.rename(columns={'Muscle Used': 'BodyPart'}, inplace=True)  # Example

df_combined = pd.concat([df_old, df_new], ignore_index=True)  # Stacks them

print(df_combined.info())  # Check data structure
print(df_combined.head())  # Preview first rows

def generate_workout_plan(bodypart, level, days_per_week=3):
    try:
        # Encode user input
        bodypart_enc = le_bodypart.transform([bodypart])[0]
        level_enc = le_level.transform([level])[0]

        # Predict Equipment
        equipment_pred = model_eq.predict([[bodypart_enc, level_enc]])
        equipment_name = le_equipment.inverse_transform(equipment_pred)[0]

        # Get exercise details
        exercise_details = df_combined[df_combined['BodyPart'] == bodypart]
        if not exercise_details.empty:
            exercise_name = exercise_details['Exercise'].iloc[0]
            sets = exercise_details['Sets'].iloc[0]
            reps = exercise_details['Reps'].iloc[0]
            calories = exercise_details['Calories Burned'].iloc[0]
        else:
            exercise_name, sets, reps, calories = "Unknown", 3, "10-12", "N/A"

        # Create Workout Schedule
        schedule = {}
        for i in range(days_per_week):
            schedule[f"Day {i+1}"] = [
                f"{exercise_name} ({equipment_name}): {sets} sets x {reps} reps (üî• {calories} kcal)"
            ]

        return schedule

    except Exception as e:
        print(f"‚ö†Ô∏è Error: {e}")
        return None

# Example Usage
user_input = {
    'bodypart': 'Chest',
    'level': 'Intermediate',
    'days_per_week': 4
}

plan = generate_workout_plan(**user_input)

# Print Results
if plan:
    print("\nüî• Weekly Workout Plan üî•")
    for day, exercises in plan.items():
        print(f"\n{day}:")
        for ex in exercises:
            print(f"- {ex}")

import pandas as pd
import random
import os

def load_and_merge_datasets(file1, file2):
    # Check if files exist before loading
    if not os.path.exists(file1) or not os.path.exists(file2):
        raise FileNotFoundError("One or both dataset files not found. Ensure they are in the correct directory.")

    # Load datasets
    df1 = pd.read_csv(file1)
    df2 = pd.read_csv(file2)

    # Drop unnecessary columns from megaGymDataset
    df2 = df2.drop(columns=["Unnamed: 0", "Desc", "Rating", "RatingDesc"], errors='ignore')

    # Standardize column names for merging
    df1.rename(columns={"Workout_Type": "Type", "Experience_Level": "Level"}, inplace=True)

    # Convert Level in df1 to match df2
    level_mapping = {"1": "Beginner", "2": "Intermediate", "3": "Advanced"}
    df1["Level"] = df1["Level"].astype(str).map(level_mapping)

    # Standardize Type column
    df1["Type"] = df1["Type"].replace({"HIIT": "High Intensity", "Yoga": "Flexibility"})

    # Merge datasets
    merged_df = pd.merge(df1, df2, on=["Type", "Level"], how="inner")
    return merged_df

def generate_workout_plan(merged_df, body_part, workout_type, level, num_days=5):
    """
    Generates a workout schedule based on user input.

    Parameters:
    - merged_df (DataFrame): Merged dataset
    - body_part (str): Targeted muscle group (e.g., Chest, Legs, Back)
    - workout_type (str): Type of workout (e.g., Strength, Cardio)
    - level (str): Experience level (Beginner, Intermediate, Advanced)
    - num_days (int): Number of workout days in the plan (default: 5)

    Returns:
    - Dict with day-wise exercise schedule.
    """
    filtered_df = merged_df[
        (merged_df["BodyPart"].str.contains(body_part, case=False, na=False)) &
        (merged_df["Type"].str.contains(workout_type, case=False, na=False)) &
        (merged_df["Level"] == level)
    ]

    if filtered_df.empty:
        return {"Error": "No exercises found for the given inputs. Try different criteria."}

    exercises = filtered_df["Title"].unique().tolist()
    random.shuffle(exercises)

    workout_plan = {}
    for i in range(num_days):
        day = f"Day {i+1}"
        if exercises:
            exercise = exercises.pop()
            workout_plan[day] = {
                "Exercise": exercise,
                "Sets": random.choice([3, 4, 5]),
                "Reps": random.choice([8, 10, 12, 15])
            }
        else:
            workout_plan[day] = "Rest Day"

    return workout_plan

# Example usage
file1 = "/content/drive/My Drive/122Colab/gym_members_exercise_tracking.csv"
file2 = "/content/drive/My Drive/122Colab/megaGymDataset.csv"

try:
    merged_df = load_and_merge_datasets(file1, file2)
    sample_plan = generate_workout_plan(merged_df, "Chest", "Strength", "Intermediate")
    print(sample_plan)
except FileNotFoundError as e:
    print(e)

import pandas as pd
import random
import os

def load_and_merge_datasets(file1, file2):
    # Check if files exist before loading
    if not os.path.exists(file1) or not os.path.exists(file2):
        raise FileNotFoundError("One or both dataset files not found. Ensure they are in the correct directory.")

    # Load datasets
    df1 = pd.read_csv(file1)
    df2 = pd.read_csv(file2)

    # Drop unnecessary columns from megaGymDataset
    df2 = df2.drop(columns=["Unnamed: 0", "Desc", "Rating", "RatingDesc"], errors='ignore')

    # Standardize column names for merging
    df1.rename(columns={"Workout_Type": "Type", "Experience_Level": "Level"}, inplace=True)

    # Convert Level in df1 to match df2
    level_mapping = {"1": "Beginner", "2": "Intermediate", "3": "Advanced"}
    df1["Level"] = df1["Level"].astype(str).map(level_mapping)

    # Standardize Type column
    df1["Type"] = df1["Type"].replace({"HIIT": "High Intensity", "Yoga": "Flexibility"})

    # Merge datasets
    merged_df = pd.merge(df1, df2, on=["Type", "Level"], how="inner")
    return merged_df

def calculate_bmi(weight, height):
    """Calculates BMI given weight (kg) and height (m)."""
    return round(weight / (height ** 2), 2)

def get_fitness_goal(bmi, gender):
    """Suggests a workout goal based on BMI and gender."""
    if bmi < 18.5:
        return "Muscle Gain"
    elif 18.5 <= bmi < 24.9:
        return "General Fitness"
    elif 25 <= bmi < 29.9:
        return "Fat Loss"
    else:
        return "Weight Loss"

def generate_workout_plan(merged_df, body_part, workout_type, level, num_days=5):
    """
    Generates a workout schedule based on user input.

    Parameters:
    - merged_df (DataFrame): Merged dataset
    - body_part (str): Targeted muscle group (e.g., Chest, Legs, Back)
    - workout_type (str): Type of workout (e.g., Strength, Cardio)
    - level (str): Experience level (Beginner, Intermediate, Advanced)
    - num_days (int): Number of workout days in the plan (default: 5)

    Returns:
    - Dict with day-wise exercise schedule.
    """
    filtered_df = merged_df[
        (merged_df["BodyPart"].str.contains(body_part, case=False, na=False)) &
        (merged_df["Type"].str.contains(workout_type, case=False, na=False)) &
        (merged_df["Level"] == level)
    ]

    if filtered_df.empty:
        return {"Error": "No exercises found for the given inputs. Try different criteria."}

    exercises = filtered_df["Title"].unique().tolist()
    random.shuffle(exercises)

    workout_plan = {}
    for i in range(num_days):
        day = f"Day {i+1}"
        if exercises:
            exercise = exercises.pop()
            workout_plan[day] = {
                "Exercise": exercise,
                "Sets": random.choice([3, 4, 5]),
                "Reps": random.choice([8, 10, 12, 15])
            }
        else:
            workout_plan[day] = "Rest Day"

    return workout_plan

# Example usage
file1 = "/content/drive/My Drive/122Colab/gym_members_exercise_tracking.csv"
file2 = "/content/drive/My Drive/122Colab/megaGymDataset.csv"

try:
    merged_df = load_and_merge_datasets(file1, file2)

    # Get user input
    weight = float(input("Enter your weight (kg): "))
    height = float(input("Enter your height (m): "))
    gender = input("Enter your gender (Male/Female): ").strip().capitalize()
    body_part = input("Enter the body part to focus on (e.g., Chest, Legs, Back): ").strip().capitalize()
    level = input("Enter your experience level (Beginner, Intermediate, Advanced): ").strip().capitalize()

    # Calculate BMI and determine fitness goal
    bmi = calculate_bmi(weight, height)
    fitness_goal = get_fitness_goal(bmi, gender)
    print(f"Your BMI is {bmi}, and your suggested fitness goal is: {fitness_goal}")

    # Generate workout plan based on the fitness goal
    sample_plan = generate_workout_plan(merged_df, body_part, fitness_goal, level)
    print("Your Workout Plan:")
    for day, details in sample_plan.items():
        print(f"{day}: {details}")

except FileNotFoundError as e:
    print(e)